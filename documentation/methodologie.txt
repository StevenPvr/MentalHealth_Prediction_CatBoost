I - Objectif du projet 

L'objectif du projet est de prédire la variable "treatment" à partir
de l'ensemble des autres variables. Cela permettra de comprendre quelles
variables donnent le plus d'information au modèle. L'objectif étant d'investiguer 
la connexion entre le style de vie et la santé mentale.

II - Dataset

Le dataset provient de Kaggle : https://www.kaggle.com/datasets/alamshihab075/mental-health-dataset/data

Il contient 261 330 lignes, 16 features, dont 1 qui sera la target.

Il s'agit de données catégorielles individuelles sur des personnes assez variées
sur leurs antécédents, l'activité quotidienne, mais aussi l'exploration des potentiels symptômes
dépressif. 

III - Démarche méthodologique

A - Analyse exploratoire
    1. Statistiques descriptives univariées
        a. Fréquence des variables absolues et relatives
        b. Mode
        c. Nombre de valeurs uniques par variables (bruit)
    2. Statistiques descriptives bivariées
        a. Tableau de contingence
        b. Chi² et p_value
        c. Cramér's V

Le contenu du IV sera décidé après analyse Statistiques.

IV - Prétraitements et pipeline

A - Nettoyage des données
    1. Suppression des colonnes dupliquées
    2. Gestion des valeurs manquantes
    3. Normalisation des chaînes en minuscules
    4. Nettoyage des valeurs textuelles (espaces, guillemets)

B - Préparation des données
    1. Encodage/typage catégoriel
    2. Split train/val/test (60% / 20% / 20%)
    3. Sauvegarde des splits au format Parquet et CSV

V - Modélisation

A - Modèle
    1. CatBoostClassifier (adapté aux variables catégorielles)
    2. Gestion native des catégories et valeurs manquantes

B - Hyperparamètres
    1. Recherche initiale guidée par la littérature (learning_rate, depth, l2_leaf_reg)
    2. Early stopping sur l'échantillon de validation

VI - Entraînement

    1. Entraînement sur train, suivi par early stopping sur val
    2. Sauvegarde du modèle entraîné (.cbm)
    3. Journal d'entraînement CatBoost (catboost_info)

VII - Évaluation

    1. Métriques globales sur test: Logloss, AUC, Accuracy, F1, Recall
    2. Cross-validation stratifiée 5-fold pour mesurer la stabilité du modèle
    3. Export des résultats sous forme JSON et Markdown (dossier results/)
    4. Visualisation SHAP (impact directionnel moyen par variable)

VIII - Équité (Fairness)

    1. Évaluation par groupe sensible (ex: gender)
    2. Évaluation par pays (country)
    3. Indicateurs d'écarts (ex: AUC gap max-min)
    4. Mise en garde: interpréter avec prudence en cas de déséquilibres de classes

IX - Interprétabilité

    1. SHAP summary (mean |SHAP|) pour identifier les variables contributrices
    2. Analyse des top features et cohérence métier

X - Reproductibilité et Organisation

    1. Orchestration via src/main_global.py (clean -> prepare -> train -> eval)
    2. Environnement Python isolé (virtualenv)
    3. Contrôle de versions et .gitignore (données et artefacts lourds exclus)

XI - Limites et perspectives

    1. Qualité et bruit des données (catégorielles, valeurs manquantes, questionnaire auto-déclaré)
    2. Biais potentiels par groupes (fairness)
    3. Pistes: tuning d'hyperparamètres, calibration, méthodes d'atténuation des biais, variance sur l'évaluation, warning sur les tests